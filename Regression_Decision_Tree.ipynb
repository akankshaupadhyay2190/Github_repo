{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regression Decision Tree Algorithm for predicting pollutant NO2\n",
    "## Developer: Akanksha Upadhyay\n",
    "## Date: 12/02/2025\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Load the data\n",
    "data = pd.read_csv(r\"data.csv\")\n",
    "print(data.head())\n",
    "print(data.describe())\n",
    "\n",
    "## removing null\n",
    "print(data.isnull().sum())\n",
    "data.dropna(inplace=True)\n",
    "print(data.info())\n",
    "\n",
    "\n",
    "\n",
    "# separating features (root nodes) and target (leaf nodes)\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data[['traffic_count', 'temp', 'wind_speed', 'wind_direction',\n",
    "                           'rel_humidity', 'air_pressure']]  # Features\n",
    "y = data['NO2']  # Target variable\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "## Measure the model performance, use different max depth and max no of features\n",
    "# calculate R2 score with mse and mae\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Function to evaluate performance for different max_depth and max_features\n",
    "def evaluate_decision_tree(X_train, y_train, max_depths, max_features_list):\n",
    "    results = []\n",
    "\n",
    "    # Calculate variance of the target variable (y_train)\n",
    "    variance_y = np.var(y_train)\n",
    "    print(f\"Variance of NO2 (Training Data): {variance_y:.3f}\")\n",
    "\n",
    "    for max_depth in max_depths:\n",
    "        for max_features in max_features_list:\n",
    "            # Train the model on the training set\n",
    "            tree_model = DecisionTreeRegressor(max_depth=max_depth, max_features=max_features, random_state=42)\n",
    "            tree_model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on the training set\n",
    "            y_pred_train = tree_model.predict(X_train)\n",
    "\n",
    "            # Calculate metrics on the training data\n",
    "            r2 = r2_score(y_train, y_pred_train)\n",
    "            mae = mean_absolute_error(y_train, y_pred_train)\n",
    "            rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "\n",
    "            # Append results\n",
    "            results.append((max_depth, max_features, r2, mae, rmse))\n",
    "\n",
    "            # Print metrics for training data\n",
    "            print(f\"max_depth={max_depth}, max_features={max_features} -> Train R²: {r2:.3f}, Train MAE: {mae:.3f}, Train RMSE: {rmse:.3f}\")\n",
    "\n",
    "    # Return as a DataFrame for easy handling\n",
    "    return pd.DataFrame(results, columns=['max_depth', 'max_features', 'R2', 'MAE', 'RMSE'])\n",
    "\n",
    "\n",
    "# Define values to test\n",
    "max_depths = [3, 5, 10, None]\n",
    "max_features_list = [1, 3, 6]\n",
    "\n",
    "# Evaluate the decision tree for these combinations\n",
    "results_df = evaluate_decision_tree(X_train, y_train, max_depths, max_features_list)\n",
    "\n",
    "\n",
    "# Subplots for R2, MAE, and RMSE\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True)  # 3 rows, 1 column\n",
    "\n",
    "# Metrics to plot\n",
    "metrics = ['R2', 'MAE', 'RMSE']\n",
    "titles = [\"R² Score vs max_depth\", \"MAE vs max_depth\", \"RMSE vs max_depth\"]\n",
    "\n",
    "# Plot each metric in a separate subplot\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    for max_features in results_df['max_features'].unique():\n",
    "        subset = results_df[results_df['max_features'] == max_features]\n",
    "        ax.plot(subset['max_depth'], subset[metric], marker=\"o\", label=f'max_features={max_features}')\n",
    "    \n",
    "    ax.set_title(titles[i])\n",
    "    ax.set_xlabel(\"max_depth\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# taking the best combo of parmeters max_depth=10, max_features=6\n",
    "# criterion='squared_error' is default\n",
    "# min_samples_split=2, min_samples_leaf = 1 ## default values\n",
    "# we can use other criterian also like 'friedman_mse', 'poisson', and 'mae' based on target variable\n",
    "# Create a single decision tree and training it\n",
    "\n",
    "tree_model = DecisionTreeRegressor(max_depth=10, max_features=6, criterion='squared_error', min_samples_split=7, min_samples_leaf = 5, random_state=42)  \n",
    "tree_model.fit(X_train, y_train)  # Train the tree\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(15, 8))\n",
    "plot_tree(tree_model, feature_names=X.columns, filled=True, rounded=True, fontsize=10)\n",
    "plt.title(\"Decision Tree for Predicting NO2\")\n",
    "plt.show()\n",
    "# Predict on the test data\n",
    "y_pred_test = tree_model.predict(X_test)\n",
    "print(y_pred_test)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"Test R² Score: {r2_test:.3f}\")\n",
    "print(f\"Test MAE: {mae_test:.3f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.3f}\")\n",
    "\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test.values, label='Actual Values', color='blue', linewidth=2)\n",
    "plt.plot(y_pred_test, label='Predicted Values', color='orange', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('NO2 Values')\n",
    "plt.title('Actual vs Predicted NO2 Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Feature Importance for the decision tree\n",
    "\n",
    "feature_importances = tree_model.feature_importances_\n",
    "\n",
    "for name, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"{name}: {importance:.3f}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(X.columns, feature_importances, color=\"green\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance for Decision Tree\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
