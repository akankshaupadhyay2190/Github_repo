{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "## Load the data\n",
    "df = pd.read_csv(r\"data.csv\", parse_dates=['utctime'])\n",
    "\n",
    "## Change into date time format\n",
    "df['utctime'] = pd.to_datetime(df['utctime'], format = '%Y-%m-%d', errors  = 'coerce')\n",
    "df.sort_values(by='utctime', inplace=True)\n",
    "\n",
    "## Normalization of features\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[['water_level', 'sea_level', 'temp', 'pump1_status']] = scaler.fit_transform(df[['water_level', 'sea_level', 'temp', 'pump1_status']])\n",
    "print(df.head())\n",
    "## Making segments of data to avoid blanks in the data\n",
    "\n",
    "\n",
    "# Create segments to avoid gaps in data\n",
    "def create_segments(df: pd.DataFrame) -> list:\n",
    "    segments = []\n",
    "    current_segment = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if i == 0:\n",
    "            # For the first row, add it directly to the current segment\n",
    "            current_segment.append(df.iloc[i])\n",
    "        else:\n",
    "            # Calculate the time difference between the current and previous row\n",
    "            time_diff = df['utctime'].iloc[i] - df['utctime'].iloc[i - 1]\n",
    "            if time_diff <= pd.Timedelta(minutes=60):\n",
    "                # If the time difference is less than or equal to 60 minutes, add the row to the current segment\n",
    "                current_segment.append(df.iloc[i])\n",
    "            else:\n",
    "                # If the time difference is greater than 60 minutes, end the current segment\n",
    "                # Convert the current segment list to a DataFrame and append it to segments\n",
    "                segments.append(pd.DataFrame(current_segment))\n",
    "                # Start a new segment with the current row\n",
    "                current_segment = [df.iloc[i]]\n",
    "\n",
    "    # Append the last segment\n",
    "    if current_segment:\n",
    "        segments.append(pd.DataFrame(current_segment))\n",
    "    \n",
    "\n",
    "    return segments\n",
    "\n",
    "segments = create_segments(df)\n",
    "\n",
    "print(f\"Number of segments: {len(segments)}\")\n",
    "print(segments[0])\n",
    "\n",
    "# Define parameters as feature\n",
    "param = ['water_level', 'sea_level', 'temp', 'pump1_status']\n",
    "\n",
    "# takes data_segment (segments that we created from data)\n",
    "# Seq_inp_lenght (the lenght of each sequnce)\n",
    "# seq_out_lenght (the length of minutes we are predicting)\n",
    "# param (features)\n",
    "# first_hr is the initial part of seq that needed to be converted in hours\n",
    "# last_hour is the total period of sequnce\n",
    "# step (it is created to get output at particular intervals instead every minute)\n",
    "# Create sequences function\n",
    "def create_sequences(data_segments: list, seq_inp_length: int, seq_out_length: int, param: list) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    hour_sequences = []\n",
    "    minute_sequences = []\n",
    "    pump_fut_seq, ys = [], []\n",
    "    \n",
    "    for segment in data_segments:\n",
    "        segment = segment[param].values\n",
    "        for i in range(len(segment) - seq_inp_length - seq_out_length + 1):\n",
    "            # Input sequence for the first 12 hours (hourly averaged data)\n",
    "            hour_start_idx = i\n",
    "            hour_end_idx = i + 24 * 60\n",
    "            hour_data = segment[hour_start_idx:hour_end_idx]\n",
    "\n",
    "            hour_averaged = []\n",
    "            for j in range(0, len(hour_data), 60):\n",
    "                hour_averaged.append(np.mean(hour_data[j:j + 60, :], axis=0))     ## : all param taken for hourly data\n",
    "            hour_averaged = np.array(hour_averaged)\n",
    "\n",
    "            # Input sequence for the next 12 hours (minute-level data)\n",
    "            minute_start_idx = i + 12 * 60\n",
    "            minute_end_idx = i + seq_inp_length\n",
    "            minute_data = segment[minute_start_idx:minute_end_idx, :]  \n",
    "\n",
    "            # Known future values for pump1_status in the last 12 hours (minute-level)\n",
    "            pump1_future = segment[minute_end_idx:minute_end_idx + seq_out_length:60, 3].reshape(-1, 1)\n",
    "                     \n",
    "            # Output sequence for water_level\n",
    "            y = segment[minute_end_idx:minute_end_idx + seq_out_length:60, 0]  # Predicting next 12 hours, hourly\n",
    "\n",
    "            hour_sequences.append(hour_averaged)\n",
    "            minute_sequences.append(minute_data)\n",
    "            pump_fut_seq.append(pump1_future)\n",
    "            ys.append(y)\n",
    "\n",
    "    return np.array(hour_sequences), np.array(minute_sequences), np.array(pump_fut_seq), np.array(ys)\n",
    "\n",
    "### calling segments from above cell\n",
    "\n",
    "\n",
    "print(f\"Number of segments: {len(segments)}\")\n",
    "\n",
    "# making sequnces\n",
    "\n",
    "SEQ_INP_LENGTH = 24 * 60  # 24 hours of input data in minutes\n",
    "SEQ_OUT_LENGTH = 12 * 60  # 12 hours of output data in minutes\n",
    "\n",
    "\n",
    "hour_sequences, minute_sequences, pump_fut_seq, ys = create_sequences(segments, SEQ_INP_LENGTH, SEQ_OUT_LENGTH, param)\n",
    "\n",
    "## Now first three are input sequences and \n",
    "print(\"hour_sequences:\", hour_sequences.shape)\n",
    "print(\"minute_sequences:\", minute_sequences.shape)\n",
    "print(\"pump_fut_stat:\", pump_fut_seq.shape)\n",
    "print(\"ys:\", ys.shape)\n",
    "# Define the validation size\n",
    "val_size = int(len(hour_sequences) * 0.2)\n",
    "\n",
    "# Manually split the data into training and validation sets\n",
    "hour_val, hour_train = hour_sequences[:val_size], hour_sequences[val_size:]\n",
    "minute_val, minute_train = minute_sequences[:val_size], minute_sequences[val_size:]\n",
    "pump_val, pump_train = pump_fut_seq[:val_size], pump_fut_seq[val_size:]\n",
    "y_val, y_train = ys[:val_size], ys[val_size:]\n",
    "\n",
    "print(\"hour_train shape:\", hour_train.shape)\n",
    "print(\"hour_val shape:\", hour_val.shape)\n",
    "print(\"minute_train shape:\", minute_train.shape)\n",
    "print(\"minute_val shape:\", minute_val.shape)\n",
    "print(\"pump_train shape:\", pump_train.shape)\n",
    "print(\"pump_val shape:\", pump_val.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "### visualizing weights\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(r\"LSTM_multi_model_steps.h5\")\n",
    "\n",
    "# Print the model summary (optional, but helpful to understand the model structure)\n",
    "model.summary()\n",
    "\n",
    "# Get the model weights\n",
    "weights = model.get_weights()\n",
    "\n",
    "# Print the weights\n",
    "for i, weight in enumerate(weights):\n",
    "    print(f\"Layer {i+1} weights: {weight}\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the first layer has weights\n",
    "first_layer_weights = weights[0]\n",
    "\n",
    "# Plot the weights\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.imshow(first_layer_weights, aspect='auto', cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title(\"First Layer Weights\")\n",
    "plt.show()\n",
    "# Make predictions on the training set\n",
    "y_train_pred = model.predict([hour_train, minute_train, pump_train])\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = model.predict([hour_val, minute_val, pump_val])\n",
    "\n",
    "print(y_train.shape, y_train_pred.shape)\n",
    "\n",
    "print(y_val.shape, y_val_pred.shape)\n",
    "y_train_inverse = [\n",
    "    scaler.inverse_transform(\n",
    "        np.concatenate((y_train[:, hours_ahead-1].reshape(-1, 1), np.zeros((y_train.shape[0], len(param) - 1))), axis=1)\n",
    "    )[:, 0] \n",
    "    for hours_ahead in range(1, 13)\n",
    "]\n",
    "\n",
    "y_train_pred_inverse = [\n",
    "    scaler.inverse_transform(\n",
    "        np.concatenate((y_train_pred[:, hours_ahead-1].reshape(-1, 1), np.zeros((y_train_pred.shape[0], len(param) - 1))), axis=1)\n",
    "    )[:, 0] \n",
    "    for hours_ahead in range(1, 13)\n",
    "]\n",
    "y_val_inverse = [\n",
    "    scaler.inverse_transform(\n",
    "        np.concatenate((y_val[:, hours_ahead-1].reshape(-1, 1), np.zeros((y_val.shape[0], len(param) - 1))), axis=1)\n",
    "    )[:, 0] \n",
    "    for hours_ahead in range(1, 13)\n",
    "]\n",
    "y_val_pred_inverse = [\n",
    "    scaler.inverse_transform(\n",
    "        np.concatenate((y_val_pred[:, hours_ahead-1].reshape(-1, 1), np.zeros((y_val_pred.shape[0], len(param) - 1))), axis=1)\n",
    "    ) [:, 0] \n",
    "    for hours_ahead in range(1, 13)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "y_train_inverse = np.column_stack(y_train_inverse)\n",
    "y_train_pred_inverse = np.column_stack(y_train_pred_inverse)\n",
    "y_val_inverse = np.column_stack(y_val_inverse)\n",
    "y_val_pred_inverse = np.column_stack(y_val_pred_inverse)\n",
    "\n",
    "print(y_train_inverse.shape, y_val_pred_inverse.shape)\n",
    "print(y_train_inverse)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "\n",
    "\n",
    "plt.plot(y_train_inverse[5], label='Actual')\n",
    "plt.plot(y_train_pred_inverse[5], label='Predicted')\n",
    "plt.title('Train_data')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('cm')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "\n",
    "\n",
    "plt.plot(y_val_inverse[5], label='Actual')\n",
    "plt.plot(y_val_pred_inverse[5], label='Predicted')\n",
    "plt.title('val_data')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('cm')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "### errors for each hour\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "mae = [mean_absolute_error(y_train_inverse[:, hour], y_train_pred_inverse[:, hour]) for hour in range(y_train_inverse.shape[1])]\n",
    "mse = [mean_squared_error(y_train_inverse[:, hour], y_train_pred_inverse[:, hour]) for hour in range(y_train_inverse.shape[1])] \n",
    "rmse = np.sqrt(mse)\n",
    "mape = [mean_absolute_percentage_error(y_train_inverse[:, hour], y_train_pred_inverse[:, hour]) for hour in range(y_train_inverse.shape[1])] \n",
    "\n",
    "print(mae, mse, rmse, mape)\n",
    "\n",
    "\n",
    "## make a data frame \n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "errors = pd.DataFrame({\n",
    "    'Hour': range(1, 12 + 1),\n",
    "    'MAE': mae,\n",
    "    'MSE': mse,\n",
    "    'RMSE': rmse,\n",
    "    'MAPE': mape\n",
    "})\n",
    "\n",
    "## save as csv\n",
    "errors.to_csv(r\"LSTM_conc_errors.csv\")\n",
    "\n",
    "# simple model\n",
    "\n",
    "def predict_and_get_true_values_simple_model(y: list, time_steps_ahead: int) -> tuple[list, list]:\n",
    "    y_predict = []\n",
    "    y_true = []\n",
    "    for i in range(0, len(y)-time_steps_ahead):\n",
    "        y_predict.append(y[i])\n",
    "        y_true.append(y[i+time_steps_ahead])\n",
    "    return y_predict, y_true\n",
    "\n",
    "\n",
    "def predict_and_get_true_values_for_all_segments(time_steps_ahead: int) -> tuple[list, list]:\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    for segment in segments:\n",
    "        y = segment[\"vandindtag_cm\"].values\n",
    "        y = scaler.inverse_transform(\n",
    "            np.concatenate((y.reshape(-1, 1),\n",
    "                           np.zeros((y.shape[0], len(param) - 1))), axis=1)\n",
    "        )\n",
    "        y = y[:, 0]\n",
    "        y_pred, y_true = predict_and_get_true_values_simple_model(\n",
    "            y, time_steps_ahead)\n",
    "        y_preds.extend(y_pred)\n",
    "        y_trues.extend(y_true)\n",
    "    return y_preds, y_trues\n",
    "\n",
    "# predict_and_get_true_values_for_all_segments(60*5)\n",
    "\n",
    "\n",
    "time_steps_ahead = 60*12\n",
    "y_preds, y_trues = predict_and_get_true_values_for_all_segments(\n",
    "    time_steps_ahead)\n",
    "\n",
    "\n",
    "y_preds\n",
    "mae_simple = []\n",
    "mse_simple = []\n",
    "rmse_simple = []\n",
    "mape_simple = []\n",
    "\n",
    "\n",
    "for i in range(1, 13):\n",
    "    y_preds, y_trues = predict_and_get_true_values_for_all_segments(\n",
    "    i * 60)\n",
    "    mae_simple.append(mean_absolute_error(y_trues, y_preds))\n",
    "    mse_simple.append(mean_squared_error(y_trues, y_preds))\n",
    "    rmse_simple = np.sqrt(mse_simple)\n",
    "    mape_simple.append(mean_absolute_percentage_error(y_trues, y_preds))\n",
    "\n",
    "print(mae_simple, mse_simple, rmse_simple, mape_simple)\n",
    "## make a data frame \n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "errors_simple = pd.DataFrame({\n",
    "    'Hour': range(1, 12 + 1),\n",
    "    'MAE': mae_simple,\n",
    "    'MSE': mse_simple,\n",
    "    'RMSE': rmse_simple,\n",
    "    'MAPE': mape_simple\n",
    "})\n",
    "\n",
    "## save as csv\n",
    "errors_simple.to_csv(r\"errors_simple_model1.csv\")\n",
    "### plot for LSTM model and simple model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "errors = pd.read_csv(r\"LSTM_conc_errors.csv\")\n",
    "\n",
    "\n",
    "# Plotting the data with labels and styles\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size for better visibility\n",
    "\n",
    "plt.plot(errors['Hour'], errors['MAE'], label='LSTM_MAE', marker='o', linestyle='-', color='b')\n",
    "\n",
    "plt.plot(errors['Hour'], errors['RMSE'], label='LSTM_RMSE', marker='o', linestyle='-', color='g')\n",
    "\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Time (hours)', fontsize=12)\n",
    "plt.ylabel('Model_Error (cm)', fontsize=12)\n",
    "plt.title('LSTM Model error', fontsize=14)\n",
    "\n",
    "# Adding grid lines for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "# Adding legend with better placement\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=12)\n",
    "\n",
    "### plot for LSTM model and simple model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "errors = pd.read_csv(r\"LSTM_conc_errors.csv\")\n",
    "errors_simple = pd.read_csv(r\"errors_simple_model1.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the data with labels and styles\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size for better visibility\n",
    "\n",
    "plt.plot(errors['Hour'], errors['MAE'], label='LSTM_MAE', marker='o', linestyle='-', color='b')\n",
    "plt.plot(errors_simple['Hour'], errors_simple['MAE'], label='SIM_MAE', marker='s', linestyle='--', color='r')\n",
    "plt.plot(errors['Hour'], errors['RMSE'], label='LSTM_RMSE', marker='o', linestyle='-', color='g')\n",
    "plt.plot(errors_simple['Hour'], errors_simple['RMSE'], label='SIM_RMSE', marker='s', linestyle='--', color='y')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Time (hours)', fontsize=12)\n",
    "plt.ylabel('MOdel_Error (cm)', fontsize=12)\n",
    "plt.title('Comparison of Simple Model with LSTM Model', fontsize=14)\n",
    "\n",
    "# Adding grid lines for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Annotate labels directly on the curves\n",
    "for i, txt in enumerate(errors['MAE']):\n",
    "    if i == len(errors['MAE']) - 1:  # Annotate at the end of the line\n",
    "        plt.annotate('MAE_LSTM Model', (errors['Hour'][i], errors['MAE'][i]), textcoords=\"offset points\", xytext=(10,10), ha='center', fontsize=12, color='b')\n",
    "\n",
    "for i, txt in enumerate(errors_simple['MAE']):\n",
    "    if i == len(errors_simple['MAE']) - 1:  # Annotate at the end of the line\n",
    "        plt.annotate('MAE_Simple Model', (errors_simple['Hour'][i], errors_simple['MAE'][i]), textcoords=\"offset points\", xytext=(10,10), ha='center', fontsize=12, color='r')\n",
    "\n",
    "\n",
    "for i, txt in enumerate(errors['RMSE']):\n",
    "    if i == len(errors['RMSE']) - 1:  # Annotate at the end of the line\n",
    "        plt.annotate('RMSE_LSTM Model', (errors['Hour'][i], errors['RMSE'][i]), textcoords=\"offset points\", xytext=(10,10), ha='center', fontsize=12, color='g')\n",
    "\n",
    "for i, txt in enumerate(errors_simple['RMSE']):\n",
    "    if i == len(errors_simple['RMSE']) - 1:  # Annotate at the end of the line\n",
    "        plt.annotate('RMSE_Simple Model', (errors_simple['Hour'][i], errors_simple['RMSE'][i]), textcoords=\"offset points\", xytext=(10,10), ha='center', fontsize=12, color='y')\n",
    "\n",
    "\n",
    "# Adding legend with better placement\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=12)\n",
    "\n",
    "# Adding markers for better distinction\n",
    "plt.plot(errors['Hour'], errors['MAE'], 'bo')  # Blue circles for LSTM model\n",
    "plt.plot(errors_simple['Hour'], errors_simple['MAE'], 'rs')  # Red squares for Simple model\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "import pandas as pd\n",
    "\n",
    "history = pd.read_csv(r\"LSTM_conc_model_history.csv\")\n",
    "\n",
    "# Plot the training and validation loss: it is done to see if the model is convergig or not\n",
    "# When loss curve decrease and becomes eventually statble, it means the model is training\n",
    "# validation loss doesn't vary much and decreases very slowly because the model is trained\n",
    "# and thus it is lower than loss curve\n",
    "\n",
    "\n",
    "# Plot training and validation loss curves\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Function to create sequences for future predictions\n",
    "def create_future_sequences(df: pd.DataFrame, seq_inp_length: int, param: list) -> tuple:\n",
    "    segment = df[param].values[-seq_inp_length:]\n",
    "    hour_data = [np.mean(segment[j:j + 60, :], axis=0) for j in range(0, seq_inp_length, 60)]\n",
    "    hour_data = np.array(hour_data).reshape(1, -1, len(param))\n",
    "    minute_data = segment[-12 * 60:].reshape(1, -1, len(param))\n",
    "    return hour_data, minute_data\n",
    "\n",
    "\n",
    "# Prepare data for future predictions\n",
    "SEQ_INP_LENGTH = 24 * 60  # 24 hours of input data in minutes\n",
    "param = ['water_level', 'sea_level', 'temp', 'pump1_status']\n",
    "last_24_hours = df[-SEQ_INP_LENGTH:]\n",
    "hour_data, minute_data = create_future_sequences(last_24_hours, SEQ_INP_LENGTH, param)\n",
    "print(hour_data.shape)\n",
    "print(minute_data.shape)\n",
    "# Assume future pump1_pct values are known or kept constant\n",
    "future_pump1_pct = np.tile(minute_data[0, -1, 3], (12, 1)).reshape(1, -1, 1)\n",
    "future_pump1_pct.shape\n",
    "# Make future predictions\n",
    "future_predictions = model.predict([hour_data, minute_data, future_pump1_pct])\n",
    "print(\"Future Predictions (normalized):\", future_predictions)\n",
    "# Ensure future_predictions is a numpy array\n",
    "future_predictions = np.array(future_predictions)\n",
    "# Inverse transform the future predictions\n",
    "future_predictions_inverse = [\n",
    "    scaler.inverse_transform(\n",
    "        np.concatenate((future_predictions[:, hours_ahead-1].reshape(-1, 1), np.zeros((future_predictions.shape[0], len(param) - 1))), axis=1)\n",
    "    )[:, 0] for hours_ahead in range(1, 13)\n",
    "]\n",
    "future_predictions_inverse = np.column_stack(future_predictions_inverse)\n",
    "print(\"Future Predictions (inverse transformed):\", future_predictions_inverse)\n",
    "# Combine predictions with original data\n",
    "future_dates = [df['utctime'].iloc[-1] + pd.Timedelta(hours=i) for i in range(1, 13)]\n",
    "future_df = pd.DataFrame({\n",
    "    'utctime': future_dates,\n",
    "    #'vandindtag_cm': future_predictions_inverse.flatten()\n",
    "    'vandindtag_cm': future_predictions.flatten()\n",
    "})\n",
    "# Check the shapes of the dataframes\n",
    "print(\"Original DataFrame shape:\", df.shape)\n",
    "print(\"Future DataFrame shape:\", future_df.shape)\n",
    "\n",
    "combined_df = pd.concat([df[['utctime', 'water_level']], future_df])\n",
    "\n",
    "combined_df.shape\n",
    "\n",
    "inverse_array = scaler.inverse_transform(np.concatenate((combined_df[\"water_level\"].values.reshape(-1, 1),\n",
    "                       np.zeros((combined_df.shape[0], len(param) - 1))), axis=1)\n",
    "    )[:, 0]\n",
    "# import importlib\n",
    "# importlib.reload(plt)\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(combined_df['utctime'],\n",
    "         inverse_array, label='Original + Predicted')\n",
    "plt.axvline(x=df['utctime'].iloc[-1], color='r',\n",
    "            linestyle='--', label='Prediction Start')\n",
    "plt.xlim(combined_df.iloc[-10000]['utctime'], combined_df.iloc[-1]['utctime'])\n",
    "#plt.ylim(120, 180)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('water_level')\n",
    "plt.title('Original Data and Future Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
